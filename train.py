# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yrfB66bKCnoe1zL7FkwnHhN-pRUyLFbZ
"""

import os
from numba import jit, cuda
import cv2
import torch
import numpy as np
from google.colab import drive
drive.mount('/content/drive')

index_to_emp_name=[]
train_input_data=[]
#cascade classifier to obatin the faces in the image
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
#function to get array of pairs of images:[(p1),(p2)......,(pn)]
def pairs(t,n):
  T=[]
  for i in range (0,n-1):
    for j in range(i+1,n):
      T2=[]
      T2.append(t[i])
      T2.append(t[j]) 
      T.append(T2)
  return T 

#reshaping images
def reshape(img):
  img = cv2.resize(img,(100,100))
  return img
#formatting the input to usable data 
def format(path):
  img = cv2.imread(path)
  img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)
  #getting coordinates of faces
  rects = np.array(face_cascade.detectMultiScale(img,1.2,10))
  #if number of faces in the image is 1,then only the face is selected.else, whole image will be passed on 
  img2=[[-1]]
  if rects.shape[0]==1:
    (x,y,w,h) = rects[0]
    img = img[y:y+h,x:x+w]
    img = reshape(img)
    img=img.reshape(100,100)
    img = np.array(img,dtype=np.float64)
    img2 =img
  return img2
#accessing data from google drive
root = '/content/drive/My Drive/trainset'
j=0
#accessing the directory structure you have provided
t=[]
s=0
train_input_data2=[]
for f in os.listdir(root):
  for f2 in os.listdir(root+'/'+f):
    index_to_emp_name.append(f2)
    i=0
    temp_arr=[]
    k=0
    for f3 in os.listdir(root+'/'+f+'/'+f2):
      t2=format(root+'/'+f+'/'+f2+'/'+f3)
      if t2[0][0]!=-1:
        temp_arr.append(t2)
        i+=1
      if i>5:
        break
      if k<1 and t2[0][0]!=-1:
        train_input_data2.append(t2)
      k+=1
    m=pairs(temp_arr,i)
    for x in m:
      train_input_data.append(x)
train_input_data = np.array(train_input_data)
print(train_input_data.shape)
np.savez('input_data',train_input_data,train_input_data2)

file = np.load('input_data.npz')
def pairs(t,n):
  T=[]
  for i in range (0,n-1):
    for j in range(i+1,n):
      T2=[]
      T2.append(t[i])
      T2.append(t[j]) 
      T.append(T2)
  return T 
train_input_data2=pairs(file['arr_1'],840)
train_input_data = file['arr_0']

print(len(train_input_data))
final_input=[]
i=0
while i<=3000:
  t=[]
  t2=[]
  t3=[]
  print(i)
  j2=0
  for j in range(0,100):
    t2.append(train_input_data[i+j])
    t3.append(train_input_data2[i+j])
  i+=99
  t.append(t2)
  t.append(t3)
  final_input.append(t)

###### TRAINING THE ML MODEL TO IDENTIFY EMPLOYEE BY HIS SELFIE ######*-m
###### TRAINING THE ML MODEL TO IDENTIFY EMPLOYEE BY HIS SELFIE ######
import torch.nn.functional as F
import torch.optim as optim
import torch
import torch.nn as nn
device = torch.device("cpu")
if torch.cuda.is_available():
  device = torch.device("cuda:0")

class Network(nn.Module):
  def __init__(self):
    super(Network,self).__init__()
    self.conv1 = nn.Conv2d(in_channels=1,out_channels=5,kernel_size=30)
    self.conv2 = nn.Conv2d(in_channels=5,out_channels=10,kernel_size=10)
    self.conv3 = nn.Conv2d(in_channels=10,out_channels=10,kernel_size=5)
    self.fc1 = nn.Linear(in_features=160,out_features=100)
    self.fc2 = nn.Linear(in_features=100,out_features=50)
    self.fc3 = nn.Linear(in_features=50,out_features=20)
    self.fc4 = nn.Linear(in_features=20,out_features=1)

  def forward(self,t1,t2):
    m = nn.Sigmoid()
    t=t1
    m2 = nn.MaxPool2d(kernel_size=2,stride=2)
    t = self.conv1(t)
    t = F.relu(t)
    t = m2(t)
    t = self.conv2(t)
    t = F.relu(t)
    t = m2(t)
    t = self.conv3(t)
    t = F.relu(t)
    t = m2(t)
    t = t.reshape(1,160)
    t = self.fc1(t)
    t =F.relu(t)
    t = self.fc2(t)
    t = F.relu(t)
    t = self.fc3(t)
    t = F.relu(t)
    t = self.fc4(t)
    t =  m(t)
    t2 = self.conv1(t2)
    t2 = F.relu(t2)
    t2 = m2(t2)
    t2 = self.conv2(t2)
    t2 = F.relu(t2)
    t2 = m2(t2)
    t2 = self.conv3(t2)
    t2 = F.relu(t2)
    t2 = m2(t2)
    t2 = t2.reshape(1,160)
    t2 = self.fc1(t2)
    t2 = F.relu(t2)
    t2 = self.fc2(t2)
    t2 = F.relu(t2)
    t2 = self.fc3(t2)
    t2 = F.relu(t2)
    t2 = self.fc4(t2)
    t2 = m(t2)
    return t,t2

class ContrastiveLoss2(torch.nn.Module):
    def __init__(self, margin=1):
        super(ContrastiveLoss2, self).__init__()
        self.margin = margin
    
    def forward(self, x0, x1, y):
        diff = x0 - x1
        dist_sq = torch.sum(torch.pow(diff, 2), 1)
        dist = torch.sqrt(dist_sq)
        mdist = self.margin - dist
        dist = torch.clamp(mdist, min=0.0)
        loss = y * dist_sq + (1 - y) * torch.pow(dist, 2)
        loss = torch.sum(loss) / 2.0 / x0.size()[0]
        return loss


net = Network().to(device)
net.load_state_dict(torch.load('final_model'))
net.double()
l_fun=ContrastiveLoss2()
optimizer = optim.SGD(net.parameters(),lr=0.0007)
num_of_epochs=10000
optimizer.zero_grad()
for epoch in range(0,num_of_epochs):
  print(epoch)
  for batch in final_input:
    matching_imgs=batch[0]
    unmatching_imgs=batch[1]
    i=0
    l=0
    for img_set in matching_imgs:
      img1 = torch.tensor(img_set[0],device=device).reshape(1,1,100,100)
      img2 = torch.tensor(img_set[1],device=device).reshape(1,1,100,100)
      out1,out2 = net(img1/255,img2/255)
      loss = l_fun(out1,out2,0)
      l+=loss
    for img_set in unmatching_imgs:
      img1 = torch.tensor(img_set[0],device=device).reshape(1,1,100,100)
      img2 = torch.tensor(img_set[1],device=device).reshape(1,1,100,100)
      out1,out2 = net(img1/255,img2/255)
      loss = l_fun(out1,out2,1)
      l+=loss
  print(l)
  l.backward()
  optimizer.step()
  optimizer.zero_grad()

torch.save(net.state_dict(),'final_model')